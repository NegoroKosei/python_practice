{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt.txtの説明\n",
    "# 1:フレーム数(画像データのファイル名と対応)\n",
    "# 2:物体番号\n",
    "# 3:バウンディングボックスの左上のx座標\n",
    "# 4:バウンディングボックスの左上のy座標\n",
    "# 5:バウンディングボックスの幅\n",
    "# 6:バウンディングボックスの高さ\n",
    "# 7:Confidence score (0~1)\n",
    "# 8:Class\n",
    "# 9:Visibility 視認率。(0~1)\n",
    "\n",
    "# 8のClassの説明\n",
    "# Pedestrian 1\n",
    "# Person on vehicle 2\n",
    "# Car 3\n",
    "# Bicycle 4\n",
    "# Motorbike 5\n",
    "# Non motorized vehicle 6\n",
    "# Static person 7\n",
    "# Distractor 8\n",
    "# Occluder 9\n",
    "# Occluder on the ground 10\n",
    "# Occluder full 11\n",
    "# Reflection 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連番画像の出力\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# テキストボックスの描画関数\n",
    "# 画像, テキスト, 左下座標x, 左下座標y, テキストカラー, フォントサイズ, フォント太さ, ボックスカラー\n",
    "def draw_textbox(img: np.ndarray,\n",
    "                 text: str, x: int, y: int, text_color: tuple = (255, 255, 255), font_scale: float = 1, thickness: int = 2,\n",
    "                 box_color: tuple = (255, 0, 0)) -> None:\n",
    "    # テキストのサイズを取得, テキストのベースラインを取得(テキストの下端からベースラインまでの距離)\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    # バウンディングボックスの座標を計算\n",
    "    top_left = (x, y - text_height)  # ボックス左上\n",
    "    bottom_right = (x + text_width, y)  # ボックス右下\n",
    "    # ボックスを描画(フチなし)\n",
    "    cv2.rectangle(img, top_left, bottom_right, box_color, -1)\n",
    "    # テキストを描画\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness)\n",
    "\n",
    "# 中心座標を求める関数\n",
    "def calculate_center(x, y, w, h):\n",
    "    return int((x * 2 + w) / 2.0), int((y * 2 + h) / 2.0)\n",
    "\n",
    "# 画像の保存先フォルダ\n",
    "upload_folder = 'img2\\\\'\n",
    "# フォントの設定\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "# gt.txtの読み込み, for文での読み込みよりも早い\n",
    "df = pd.read_csv('intern_data\\\\MOT17-02-DPM\\\\gt\\\\gt.txt', sep = ',', encoding='cp932', header=None)\n",
    "# フレームの数だけ繰り返す\n",
    "for frame in range(1, 601):\n",
    "    # ファイル名の作成\n",
    "    filename = f'{frame:06}'\n",
    "    input_filename = 'intern_data\\\\MOT17-02-DPM\\\\img1\\\\' + filename + '.jpg'\n",
    "    upload_filename = upload_folder + filename + '.jpg'\n",
    "\n",
    "    # input画像ファイルが存在するか確認\n",
    "    if os.path.exists(input_filename):\n",
    "        # 画像の読み込み\n",
    "        img = cv2.imread(input_filename)\n",
    "        # BGR→RGBに変換(順番入れ替え,OpenCVの仕様)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # frameのデータのみを抽出\n",
    "        frame_line = df[df.iloc[:, 0] == frame]\n",
    "        # 番号リスト (0～11)を(0～255)のunit8型配列に変換して1列に生成\n",
    "        classlist = classlist = np.linspace(0, 255, 12).astype(np.uint8).reshape(-1, 1)\n",
    "        # カラーマップを使用して色を生成 (COLORMAP_JETを使用)\n",
    "        colormap = cv2.COLORMAP_JET\n",
    "        # カラーマップを適用して3列に変換\n",
    "        color_map = cv2.applyColorMap(classlist, colormap).reshape(-1, 3)\n",
    "\n",
    "        # データの数(行数)だけ繰り返す\n",
    "        for i in range(len(frame_line)):\n",
    "            # 長方形の座標を取得\n",
    "            recx, recy, recw, rech = frame_line.iloc[i, 2:6]\n",
    "            # クラスを取得\n",
    "            reccl = frame_line.iloc[i, 7]\n",
    "            # 中心座標を求める\n",
    "            reccx, reccy = calculate_center(recx, recy, recw, rech)\n",
    "            # 座表の範囲画像内に収める\n",
    "            reclx = int(max(0, recx))\n",
    "            recly = int(max(0, recy))\n",
    "            recrx = int(min(img.shape[1], recw + recx))\n",
    "            recry = int(min(img.shape[0], rech + recy))\n",
    "            # 描画色を求める\n",
    "            color = tuple(map(int, color_map[reccl]))\n",
    "            # 長方形の描画\n",
    "            cv2.rectangle(img, (reclx, recly), (recrx, recry), color, thickness=3)\n",
    "            # ラベル(Class)の描画\n",
    "            draw_textbox(img, str(reccl), reclx, recly, text_color=(0,0,0), font_scale=0.5, thickness=2, box_color=color)\n",
    "            # 重心の描画\n",
    "            if(0 <= reccx < img.shape[1] and 0 <= reccy < img.shape[0]):\n",
    "                cv2.drawMarker(img, (reccx, reccy), (0, 255, 0), markerSize=20)\n",
    "\n",
    "        # フレーム以前のデータのみ抽出\n",
    "        frame_line = df[df.iloc[:, 0] <= frame]\n",
    "        # idの最大値を取得\n",
    "        max_id = frame_line.iloc[:, 1].max()\n",
    "        # 物体番号ごとに線を引く\n",
    "        for i in range(1, max_id + 1):\n",
    "            # 物体番号でフィルタリング\n",
    "            frame_line_cl = frame_line[frame_line.iloc[:, 1] == i]\n",
    "            # DataFrame が空の場合はスキップ\n",
    "            if frame_line_cl.empty:\n",
    "                continue\n",
    "            # 最後の行がフレームに存在しない場合はスキップ\n",
    "            if frame_line_cl.iloc[-1, 0] != frame:\n",
    "                continue\n",
    "            # データが2つ以上ない場合はスキップ\n",
    "            if len(frame_line_cl) < 2:\n",
    "                continue\n",
    "            # 色を取得\n",
    "            reccl = frame_line_cl.iloc[0, 7]\n",
    "            color = tuple(map(int, color_map[reccl]))\n",
    "            for j in range(len(frame_line_cl) - 1):\n",
    "                # 長方形の座標を取得\n",
    "                recx1, recy1, recw1, rech1 = frame_line_cl.iloc[j, 2:6]\n",
    "                rectx2, recty2, recw2, rech2 = frame_line_cl.iloc[j + 1, 2:6]\n",
    "                # 中心座標を求める\n",
    "                reccx1, reccy1 = calculate_center(recx1, recy1, recw1, rech1)\n",
    "                reccx2, reccy2 = calculate_center(rectx2, recty2, recw2, rech2)\n",
    "                # 線の描画\n",
    "                cv2.line(img, (reccx1, reccy1), (reccx2, reccy2), color, thickness = 1)\n",
    "        \n",
    "        # 画像の保存\n",
    "        # BGR→RGBに変換(順番入れ替え,OpenCVの仕様)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(upload_filename, img)\n",
    "    else:\n",
    "        print(f\"{input_filename} は存在しません。\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "動画の作成が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = 'img'  # 画像フォルダのパス\n",
    "output_video = 'movie\\\\output_video.mp4'  # 出力する動画ファイル名\n",
    "fps = 30\n",
    "\n",
    "# 画像ファイル名を取得し、ソートして存在確認\n",
    "images = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "images.sort()\n",
    "\n",
    "# 最初の画像でフレームサイズを取得\n",
    "frame = cv2.imread(images[0])\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# 動画ファイルの設定\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# 画像をフレームとして追加\n",
    "for img_path in images:\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is not None:\n",
    "        video.write(frame)\n",
    "    else:\n",
    "        print(f\"画像 {img_path} の読み込みに失敗しました。\")\n",
    "\n",
    "video.release()\n",
    "print(\"動画の作成が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1     2    3   4    5  6  7    8\n",
      "0        1   1   912  484  97  109  0  7  1.0\n",
      "1        2   1   912  484  97  109  0  7  1.0\n",
      "2        3   1   912  484  97  109  0  7  1.0\n",
      "3        4   1   912  484  97  109  0  7  1.0\n",
      "4        5   1   912  484  97  109  0  7  1.0\n",
      "...    ...  ..   ...  ...  ..  ... .. ..  ...\n",
      "29998  593  80  1043  445  32   97  1  1  0.0\n",
      "29999  594  80  1043  445  32   97  1  1  0.0\n",
      "30000  600  81  1007  451  24   69  1  1  0.0\n",
      "30001  600  82   987  473  21   43  1  1  0.0\n",
      "30002  600  83   749  449  33   96  1  1  0.5\n",
      "\n",
      "[1579 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 20歩歩行のデータを抽出\n",
    "import pandas as pd\n",
    "# gt.txtの読み込み, for文での読み込みよりも早い\n",
    "df = pd.read_csv('intern_data\\\\MOT17-02-DPM\\\\gt\\\\gt.txt', sep = ',', encoding='cp932', header=None)\n",
    "result = np.empty((0, 2))  # 0行2列の空の配列\n",
    "id_max = df.iloc[:, 1].max()\n",
    "df_top_10 = df.groupby(1).head(20)\n",
    "data_n = 0\n",
    "for i in range(1, id_max + 1):\n",
    "    df_id = df_top_10[df_top_10.iloc[:, 1] == i]\n",
    "    if(df_id.shape[0] < 10):\n",
    "        continue\n",
    "    elif((df_id.iloc[:,7] == 1).all()):\n",
    "        continue\n",
    "    else:\n",
    "        df_id_g = pd.DataFrame([df_id.iloc[:, 2] + df_id.iloc[:, 4] / 2,\n",
    "                                df_id.iloc[:, 3] + df_id.iloc[:, 5] / 2]).T\n",
    "        df_id_g = df_id_g.to_numpy()\n",
    "        result = np.vstack([result, df_id_g])\n",
    "\n",
    "# resultを.datファイルに保存\n",
    "np.savetxt('intern_data\\\\MOT17-02-DPM\\\\10stepswalk\\\\10stepswalk.dat', result, delimiter=',', fmt='%.1f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フレーム数の多い歩行者のデータを取得\n",
    "import pandas as pd\n",
    "# gt.txtの読み込み, for文での読み込みよりも早い\n",
    "df = pd.read_csv('intern_data\\\\MOT17-02-DPM\\\\gt\\\\gt.txt', sep = ',', encoding='cp932', header=None)\n",
    "df = df[df.iloc[:, 7] == 1]\n",
    "\n",
    "group_sizes = df.groupby(1).size()\n",
    "\n",
    "# 最も行数が多いグループを取得\n",
    "most_frequent_n = group_sizes.idxmax()\n",
    "# 最も行数が多いグループのデータを取得\n",
    "df = df[df.iloc[:, 1] == most_frequent_n]\n",
    "# x,y座標の中心を求める\n",
    "df_g = pd.DataFrame([df.iloc[:, 2] + df.iloc[:, 4] / 2,\n",
    "                                df.iloc[:, 3] + df.iloc[:, 5] / 2]).T\n",
    "df_g = df_g.to_numpy()\n",
    "\n",
    "# most_frequent_group_dataを.datファイルに保存\n",
    "np.savetxt('intern_data\\\\MOT17-02-DPM\\\\seriesdata\\\\seriesdata.dat', df_g, delimiter=',', fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SASAKILAB24\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - loss: 0.4530 - val_loss: 0.3657\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3532 - val_loss: 0.2729\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2612 - val_loss: 0.1927\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1945 - val_loss: 0.1245\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1303 - val_loss: 0.0685\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0884 - val_loss: 0.0299\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0478 - val_loss: 0.0154\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0440 - val_loss: 0.0192\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0402 - val_loss: 0.0213\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0464 - val_loss: 0.0158\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0342 - val_loss: 0.0090\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0235 - val_loss: 0.0057\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0211 - val_loss: 0.0057\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0202 - val_loss: 0.0064\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0146 - val_loss: 0.0066\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0164 - val_loss: 0.0059\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0116 - val_loss: 0.0044\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0097 - val_loss: 0.0032\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0107 - val_loss: 0.0027\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0079 - val_loss: 0.0022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "Actual: [742.  546.5]\n",
      "Predicted: [832.08453 529.94684]\n",
      "Mean Squared Error: 2251.300853536826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# サンプルデータの生成 (時系列データ)\n",
    "\n",
    "data = np.loadtxt('intern_data\\\\MOT17-02-DPM\\\\10stepswalk\\\\10stepswalk.dat', delimiter=',')\n",
    "\n",
    "# ウィンドウサイズを設定\n",
    "window_size = 10\n",
    "# データの列数を取得\n",
    "n_samples = data.shape[0]\n",
    "print(n_samples)\n",
    "\n",
    "# 入力データとラベルを作成\n",
    "X, Y = [], []\n",
    "for i in range(0, n_samples, window_size):\n",
    "    X.append(data[i:i + window_size-1])  # 過去の座標\n",
    "    Y.append(data[i + window_size-1])   # 次の座標\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# データのスケーリング\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X.reshape(-1, X.shape[2])).reshape(X.shape)  # Xのスケーリング\n",
    "Y = scaler.fit_transform(Y)  # Yのスケーリング\n",
    "\n",
    "# データの分割\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "\n",
    "# LSTMモデルの構築\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(window_size, 2), return_sequences=False),\n",
    "    Dense(2)  # 次のx, y座標を出力\n",
    "])\n",
    "\n",
    "# モデルのコンパイルとトレーニング\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=16, validation_data=(X_test, Y_test))\n",
    "\n",
    "# 予測\n",
    "predicted = model.predict(X_test)\n",
    "# 予測結果を元のスケールに戻す\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "# 実際の値も逆スケーリング\n",
    "Y_test_actual = scaler.inverse_transform(Y_test)\n",
    "\n",
    "# グラフの作成\n",
    "# 日本語フォントを指定 (IPAexGothicを使用)\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "# 図の作成とサイズ指定\n",
    "plt.figure(figsize=(5, 5))  # 幅8インチ、高さ8インチ\n",
    "# 散布図を描画\n",
    "plt.scatter(Y_test_actual, predicted, color='red',s = 5)\n",
    "# 内向きの目盛りを設定\n",
    "plt.tick_params(direction='in', which='both')  # 'both' でx軸とy軸両方の目盛りを内向きに\n",
    "\n",
    "plt.xlabel(r'テストデータ',fontsize=15)\n",
    "plt.ylabel('予測データ',fontsize=15)\n",
    "plt.legend()             # 凡例を表示\n",
    "# plt.xlim(min(x1), max(x1)/2) # X軸の範囲を調整\n",
    "# plt.ylim(0, max(y)+0.5)  # Y軸の範囲を調整\n",
    "# グラフを画像として保存 (PNG形式)\n",
    "plt.savefig('graph/predicted.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Actual:\", Y_test_actual[0])\n",
    "print(\"Predicted:\", predicted[0])\n",
    "# モデル評価\n",
    "mse = mean_squared_error(Y_test_actual, predicted)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SASAKILAB24\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - loss: 0.1552 - val_loss: 0.1238\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.7133e-04 - val_loss: 0.0015\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0479e-04 - val_loss: 0.0016\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.1840e-05 - val_loss: 0.0017\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.2589e-05 - val_loss: 0.0017\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 9.3410e-05 - val_loss: 0.0020\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.3092e-05 - val_loss: 0.0018\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.5845e-05 - val_loss: 0.0018\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.6292e-05 - val_loss: 0.0020\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.1073e-05 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.7459e-05 - val_loss: 0.0022\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.8409e-05 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.8884e-05 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.6347e-05 - val_loss: 0.0024\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.1247e-05 - val_loss: 0.0022\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.8265e-05 - val_loss: 0.0024\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.5720e-05 - val_loss: 0.0020\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3311e-05 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.7767e-05 - val_loss: 0.0022\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step\n",
      "Actual: [1130.5  512. ]\n",
      "Predicted: [1130.3972   511.86972]\n",
      "(118, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.084563708122236\n"
     ]
    }
   ],
   "source": [
    "# LSTM(長期記憶が得意なRNN)による歩行者データの予測\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# サンプルデータの生成 (時系列データ)\n",
    "data = np.loadtxt('intern_data\\\\MOT17-02-DPM\\\\seriesdata\\\\seriesdata.dat', delimiter=',')\n",
    "# ウィンドウサイズを設定\n",
    "window_size = 10\n",
    "# データの列数を取得\n",
    "n_samples = data.shape[0]\n",
    "\n",
    "# 入力データとラベルを作成(1づつずらす)\n",
    "X, Y = [], []\n",
    "for i in range(0, n_samples - window_size):\n",
    "    X.append(data[i:i + window_size, :])  # 過去のデータ\n",
    "    Y.append(data[i + window_size, :])   # 次の座標\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# 入力データと出力データを連結してスケーリング\n",
    "combined = np.vstack([X.reshape(-1, X.shape[2]), Y])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "combined_scaled = scaler.fit_transform(combined)\n",
    "\n",
    "# スケーリング後に分割\n",
    "X = combined_scaled[:len(X.reshape(-1, X.shape[2]))].reshape(X.shape)\n",
    "Y = combined_scaled[len(X.reshape(-1, X.shape[2])):]\n",
    "\n",
    "# データの分割\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "\n",
    "# LSTMモデルの構築\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(window_size, 2), return_sequences=False), # 隠れ層(ユニット数50)\n",
    "    Dense(2)  # 次のx, y座標を出力(全結合層)\n",
    "])\n",
    "\n",
    "# モデルのコンパイルとトレーニング\n",
    "# 最適化アルゴリズム: Adam, 損失関数: 平均二乗誤差\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=16, validation_data=(X_test, Y_test))\n",
    "\n",
    "# 予測\n",
    "predicted = model.predict(X_test)\n",
    "print(predicted.shape)\n",
    "print(X.shape)\n",
    "# 予測結果を元のスケールに戻す\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "# 実際の値も逆スケーリング\n",
    "Y_test_actual = scaler.inverse_transform(Y_test)\n",
    "\n",
    "# グラフの作成---------------------------------------------------------------------------\n",
    "# 日本語フォントを指定 (IPAexGothicを使用)\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "# 図の作成とサイズ指定\n",
    "plt.figure(figsize=(5, 5))  # 幅8インチ、高さ8インチ\n",
    "# 散布図を描画\n",
    "plt.scatter(Y_test_actual[:, 0], predicted[:, 0], color='red',s = 5)\n",
    "# 内向きの目盛りを設定\n",
    "plt.tick_params(direction='in', which='both')  # 'both' でx軸とy軸両方の目盛りを内向きに\n",
    "plt.xlabel(r'テストデータx',fontsize=15)\n",
    "plt.ylabel('予測データx',fontsize=15)\n",
    "plt.xlim(1130, 1140) # X軸の範囲を調整\n",
    "plt.ylim(1130, 1140)  # Y軸の範囲を調整\n",
    "# グラフを画像として保存 (PNG形式)\n",
    "plt.savefig('graph/predicted_x.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "# 図の作成とサイズ指定\n",
    "plt.figure(figsize=(5, 5))  # 幅8インチ、高さ8インチ\n",
    "# 散布図を描画\n",
    "plt.scatter(Y_test_actual[:, 1], predicted[:, 1], color='red',s = 5)\n",
    "# 内向きの目盛りを設定\n",
    "plt.tick_params(direction='in', which='both')  # 'both' でx軸とy軸両方の目盛りを内向きに\n",
    "plt.xlabel(r'テストデータy',fontsize=15)\n",
    "plt.ylabel('予測データy',fontsize=15)\n",
    "plt.xlim(500, 514) # X軸の範囲を調整\n",
    "plt.ylim(500, 514)  # Y軸の範囲を調整\n",
    "# グラフを画像として保存 (PNG形式)\n",
    "plt.savefig('graph/predicted_y.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# モデル評価\n",
    "mse = mean_squared_error(Y_test_actual, predicted)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 予測結果を.datファイルに保存\n",
    "i = split + window_size + 1\n",
    "with open('intern_data\\\\MOT17-02-DPM\\\\seriesdata\\\\predicted_x.dat', 'w') as f:\n",
    "    for prex,prey in predicted:\n",
    "        f.write(f'{i},{prex:.1f},{prey:.1f}\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
